% !TEX program = xelatex
\newpage


	
\section{طبقه‌بندی زبان از روی ویژگی‌های صوتی}

\subsection{تعریف مسئله و هدف}	هدف، تشخیص زبان گفتار از روی ویژگی‌های صوتی استخراج‌شده از هر فایل است. مسئله به صورت یک طبقه‌بندی چندکلاسه با ۴ زبان (آلمانی، ایتالیایی، کره‌ای، اسپانیایی) تعریف می‌شود و خروجی، برچسب زبان هر نمونه است.

\subsection{داده، ویژگی‌ها و آمار توصیفی}
\subsubsection{ساختار داده و برچسب‌ها}	داده شامل بردارهای ویژگی از فایل‌های صوتی است:
\begin{itemize}
\item تعداد کلاس‌ها $4$ (آلمانی، ایتالیایی، کره‌ای، اسپانیایی).
\item تعداد ویژگی‌ها برای هر نمونه $86$ ویژگی عددی.
\item تعداد نمونه‌های آموزش $3456$ و تعداد نمونه‌های آزمون $144$.
\end{itemize}

\subsubsection{پیش‌پردازش}	به دلیل عددی بودن ویژگی‌ها، مراحل پایه انجام شده‌اند:
\begin{enumerate}
\item \textbf{برچسب‌گذاری عددی}: برچسب‌های متنی زبان‌ها به اعداد $0$ تا $3$ تبدیل شده‌اند.
\item \textbf{مقیاس‌دهی}: هرچند مدل‌های درختی به مقیاس حساس نیستند، مدل‌های مبتنی بر فاصله/گرادیان (مانند \lr{KNN،} \lr{SVM}، \lr{MLP}، \lr{Logistic Regression}) نیازمند مقیاس‌دهی هستند. در آزمون‌های اولیه مشاهده شد که توزیع ویژگی‌های خام برای مدل‌های با عملکرد بالا مناسب است؛ بنابراین داده‌ی خام نیز ارزیابی شد.
\end{enumerate}

\subsection{مدل‌ها و روش‌ها}
\subsubsection{مدل‌های پیاده‌سازی‌شده}	برای پوشش رویکردهای مختلف یادگیری، هفت مدل انتخاب شد:
\begin{itemize}
\item \textbf{مدل‌های خطی}: \lr{Logistic Regression}.
\item \textbf{مدل‌های غیرخطی/فاصله‌محور}: \lr{KNN} و \lr{SVM}.
\item \textbf{مدل‌های درختی}: \lr{Decision Tree} و \lr{Random Forest}.
\item \textbf{شبکه‌های عصبی}: \lr{Multi-Layer Perceptron(MLP)}.
\item \textbf{مدل‌های احتمالی}: \lr{Naïve Bayes}.
\end{itemize}

\subsection{نتایج تجربی}
\subsubsection{معیارهای ارزیابی}	عملکرد مدل‌ها روی مجموعه‌ی آزمون با معیارهای \lr{Accuracy}، \lr{Precision}، \lr{Recall} و \lr{F1-Score} سنجیده شد. خلاصه‌ی نتایج در جدول زیر آمده است:

\begin{table}[H]
	\centering
	\caption{مقایسه‌ی عملکرد مدل‌ها (مرتب‌شده بر اساس دقت)}
	\begin{tabular}{lcccc}
		\toprule
		\textbf{مدل} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		\lr{Logistic Regression} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000} \\
		\lr{MLP} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000} \\
		\lr{Random Forest} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000} & \lr{1.0000}	 \\
		\lr{SVM (RBF)} & \lr{0.9931} & \lr{0.9932} & \lr{0.9931} & \lr{0.9931} \\
		\lr{KNN} & \lr{0.9861} & \lr{0.9868} & \lr{0.9861} & \lr{0.9862} \\
		\lr{Decision Tree} & \lr{0.9514} & \lr{0.9525} & \lr{0.9514} & \lr{0.9517} \\
		\lr{Naïve Bayes} & \lr{0.8264} & \lr{0.8610} & \lr{0.8264} & \lr{0.8215} \\
		\bottomrule
	\end{tabular}
\end{table}

\subsubsection{تحلیل بصری: ماتریس‌های درهم‌ریختگی}	برای بررسی دقیق‌تر، ماتریس‌های درهم‌ریختگی همه‌ی مدل‌ها رسم شده‌اند.
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{../../classifier_result/confusion_matrices.png}
	\caption{ماتریس‌های درهم‌ریختگی مدل‌های طبقه‌بندی.}
\end{figure}

\subsection{بحث و تحلیل}
\subsubsection{مقایسه‌ی مدل‌ها}	نتایج سه سطح عملکرد را نشان می‌دهد:

\paragraph{سطح ۱: مدل‌های کامل (Accuracy = 100\%)}
\textbf{\lr{Logistic Regression}، \lr{MLP} و \lr{Random Forest}} دقت کامل داشته‌اند.
\begin{itemize}
\item موفقیت \lr{Logistic Regression} نشان می‌دهد کلاس‌ها در فضای ۸۶بعدی ویژگی‌ها به‌صورت \textit{خطی جداشدنی} هستند.
\item عملکرد کامل \lr{Random Forest} و \lr{MLP} نیز قدرت سیگنال ویژگی‌ها را تأیید می‌کند، اما با توجه به موفقیت مدل خطی، پیچیدگی بیشتر ضروری نبوده است.
\end{itemize}

\paragraph{سطح ۲: مدل‌های نزدیک به کامل (Accuracy $>$ 98\%)}
\textbf{\lr{SVM} و \lr{KNN}} عملکرد بسیار بالا داشته‌اند.
\begin{itemize}
\item \lr{SVM} تنها یک نمونه را خطا کرده است؛ این نتیجه با فرض جدایی خطی سازگار است، هرچند کرنل \lr{RBF} مرز تصمیم را پیچیده‌تر کرده است.
\item \lr{KNN} نشان می‌دهد نمونه‌های هر زبان در فضای ویژگی‌ها خوشه‌بندی محلی مناسبی دارند.
\end{itemize}

\paragraph{سطح ۳: عملکرد پایین‌تر}
\textbf{\lr{Naïve Bayes}} ضعیف‌ترین نتیجه را داشته است که می‌تواند ناشی از فرض استقلال ویژگی‌ها باشد؛ ویژگی‌های گفتاری (مانند \lr{MFCC}) معمولاً هم‌بسته‌اند و این فرض نقض می‌شود.

\subsubsection{توجیه عدم استفاده از PCA و LDA}	در این پروژه از فضای خام ۸۶ ویژگی استفاده شد و کاهش‌بُعد نهایی به کار نرفت. دلایل اصلی:
\begin{enumerate}
\item \textbf{اشباع عملکرد}: دقت مدل‌ها به ۱۰۰\% رسیده و فضایی برای بهبود وجود نداشت.
\item \textbf{ریسک حذف اطلاعات (\lr{PCA})}: \lr{PCA} بر اساس واریانس عمل می‌کند، نه جدایی کلاس‌ها؛ در آزمون‌های اولیه، عملکرد برخی مدل‌ها افت داشت.
\item \textbf{جدایی خطی (\lr{LDA})}: هرچند \lr{LDA} جداسازی را در ابعاد کمتر حفظ می‌کند، اما با وجود جدایی خطی در فضای اصلی، یک مرحله‌ی اضافی و غیرضروری است.
\item \textbf{جمع‌بندی}: فضای خام کافی، پایدار و جدایی‌پذیر بوده و سادگی خط لوله حفظ شد.
\end{enumerate}

\subsection{نتیجه‌گیری}	ویژگی‌های استخراج‌شده برای تشخیص زبان بسیار تمایزبخش بوده‌اند. مدل‌های ساده‌ای مانند \lr{Logistic Regression} به دقت کامل رسیده‌اند و بنابراین بهترین انتخاب از نظر سادگی و کارایی محسوب می‌شوند. تحلیل کاهش‌بُعد نشان داد که استفاده از ویژگی‌های خام، بدون قربانی‌کردن عملکرد، خط لوله را ساده‌تر می‌کند.

